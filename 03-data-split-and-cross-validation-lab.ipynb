{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6rPLHnr98QMuqhcGnTXXw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/proffranciscofernando/introduction-to-data-science/blob/main/03-data-split-and-cross-validation-lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook for demonstration of data split and cross-validation\n",
        "\n",
        "## 1. Introduction\n",
        "This notebook provides an introduction to linear regression. We will create a synthetic dataset, fit a linear regression model, and evaluate its performance in four different scenarios:\n",
        "1. Without splitting the data\n",
        "2. With data split into training and testing sets\n",
        "3. Using cross-validation\n",
        "4. Comparing different numbers of folds in cross-validation"
      ],
      "metadata": {
        "id": "XQvqHTQfpiOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importing Libraries"
      ],
      "metadata": {
        "id": "9d1UtfFgpxBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "ja6bBsHlpy6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creating the Synthetic Dataset\n",
        "Defining the size of the dataset."
      ],
      "metadata": {
        "id": "6iAenRHLp2Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating random data\n",
        "n_samples = 100\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(n_samples, 1)\n",
        "y = 4 + 3 * X + np.random.randn(n_samples, 1)\n",
        "\n",
        "# Creating a DataFrame\n",
        "data = pd.DataFrame(data=np.hstack((X, y)), columns=['Feature', 'Target'])\n",
        "\n",
        "# Displaying the first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "HwcT1Lq3p5Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Exploratory Data Analysis (EDA)\n",
        "Visualising the relationship between Feature and Target."
      ],
      "metadata": {
        "id": "O07Rjb5Sp71I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(data['Feature'], data['Target'])\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.title('Feature vs Target')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F2Kw8PfAp_Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Scenario 1: Without Splitting the Data"
      ],
      "metadata": {
        "id": "qq8M1S7-qBvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(data[['Feature']], data['Target'])"
      ],
      "metadata": {
        "id": "sxTVmbUsqDth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the Model\n",
        "y_pred = model.predict(data[['Feature']])\n",
        "mse1 = mean_squared_error(data['Target'], y_pred)\n",
        "r2_1 = r2_score(data['Target'], y_pred)\n",
        "print(f'Scenario 1 - MSE: {mse1}')\n",
        "print(f'Scenario 1 - R²: {r2_1}')"
      ],
      "metadata": {
        "id": "IVdBCM_BqzCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Scenario 2: Splitting the Data into Training and Testing Sets"
      ],
      "metadata": {
        "id": "__8WiS6oqFJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[['Feature']], data['Target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "w060dJP-qGRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the Model on Training Data\n",
        "y_train_pred = model.predict(X_train)\n",
        "mse2_train = mean_squared_error(y_train, y_train_pred)\n",
        "r2_2_train = r2_score(y_train, y_train_pred)\n",
        "print(f'Scenario 2 - Training MSE: {mse2_train}')\n",
        "print(f'Scenario 2 - Training R²: {r2_2_train}')"
      ],
      "metadata": {
        "id": "40EPTzChqKAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the Model on Testing Data\n",
        "y_test_pred = model.predict(X_test)\n",
        "mse2_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_2_test = r2_score(y_test, y_test_pred)\n",
        "print(f'Scenario 2 - Testing MSE: {mse2_test}')\n",
        "print(f'Scenario 2 - Testing R²: {r2_2_test}')"
      ],
      "metadata": {
        "id": "s-MBb_JBqMG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Scenario 3: Using Cross-Validation"
      ],
      "metadata": {
        "id": "5dPuLi2IqOSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-Validation\n",
        "cv_mse = -cross_val_score(model, data[['Feature']], data['Target'], cv=5, scoring='neg_mean_squared_error')\n",
        "cv_r2 = cross_val_score(model, data[['Feature']], data['Target'], cv=5, scoring='r2')\n",
        "\n",
        "# Evaluating the Model\n",
        "mse3 = cv_mse.mean()\n",
        "r2_3 = cv_r2.mean()\n",
        "print(f'Scenario 3 - MSE: {mse3}')\n",
        "print(f'Scenario 3 - R²: {r2_3}')"
      ],
      "metadata": {
        "id": "LdqQQbXqqQVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Scenario 4: Comparing Different Numbers of Folds in Cross-Validation"
      ],
      "metadata": {
        "id": "P2djcfhYqUIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing different numbers of folds in cross-validation\n",
        "folds = [3, 5, 10, 20]\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "for k in folds:\n",
        "    cv_mse = -cross_val_score(model, data[['Feature']], data['Target'], cv=k, scoring='neg_mean_squared_error')\n",
        "    cv_r2 = cross_val_score(model, data[['Feature']], data['Target'], cv=k, scoring='r2')\n",
        "    mse_scores.append(cv_mse.mean())\n",
        "    r2_scores.append(cv_r2.mean())\n",
        "    print(f'{k}-fold CV - MSE: {cv_mse.mean()}')\n",
        "    print(f'{k}-fold CV - R²: {cv_r2.mean()}')"
      ],
      "metadata": {
        "id": "6AGGlH4_qU-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the results\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(folds, mse_scores, marker='o')\n",
        "plt.title('MSE vs. Number of Folds')\n",
        "plt.xlabel('Number of Folds')\n",
        "plt.ylabel('MSE')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(folds, r2_scores, marker='o')\n",
        "plt.title('R² vs. Number of Folds')\n",
        "plt.xlabel('Number of Folds')\n",
        "plt.ylabel('R²')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "80l7y4-oqcEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Comparison of All Scenarios"
      ],
      "metadata": {
        "id": "N9POjFa1qgkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing all scenarios\n",
        "#scenarios = ['No Split', 'Train/Test Split (Train)', 'Train/Test Split (Test)', '5-Fold CV', '3-Fold CV', '10-Fold CV', '20-Fold CV']\n",
        "#mse_all = [mse1, mse2_train, mse2_test, mse_cv] + mse_scores\n",
        "#r2_all = [r2_1, r2_2_train, r2_2_test, r2_cv] + r2_scores\n",
        "\n",
        "scenarios = ['No Split', 'Train/Test Split (Train)', 'Train/Test Split (Test)', '3-Fold CV', '5-Fold CV', '10-Fold CV', '20-Fold CV']\n",
        "mse_all = [mse1, mse2_train, mse2_test] + mse_scores\n",
        "r2_all = [r2_1, r2_2_train, r2_2_test] + r2_scores\n",
        "\n",
        "# Plotting the comparison\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.barh(scenarios, mse_all, color='skyblue')\n",
        "plt.xlabel('MSE')\n",
        "plt.title('Comparison of MSE across Scenarios')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.barh(scenarios, r2_all, color='lightgreen')\n",
        "plt.xlabel('R²')\n",
        "plt.title('Comparison of R² across Scenarios')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QaXY5siGqitA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Conclusion\n",
        "In this notebook, we created a synthetic dataset and fitted a linear regression model. We evaluated the model's performance using MSE and R² in four different scenarios:\n",
        "1. Without splitting the data\n",
        "2. With data split into training and testing sets\n",
        "3. Using cross-validation\n",
        "4. Comparing different numbers of folds in cross-validation\n",
        "\n",
        "Finally, we compared the results of all scenarios to understand the impact of different evaluation methods and the number of folds on the model's performance."
      ],
      "metadata": {
        "id": "S_j6W2qBqnuQ"
      }
    }
  ]
}